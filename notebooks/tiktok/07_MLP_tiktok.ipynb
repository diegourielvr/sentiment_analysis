{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Agregar el directorio raiz al PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20.32%\n",
      "Test: 4.36%\n",
      "Val: 4.36%\n",
      "(13727, 2)\n",
      "(2942, 2)\n",
      "(2942, 2)\n"
     ]
    }
   ],
   "source": [
    "from src.trainers.utils import build_datasets, save_metrics, set_seed\n",
    "from constants.constants_tiktok import TIKTOK_DATASET_SENTENCES\n",
    "\n",
    "set_seed()\n",
    "\n",
    "dataset_train, dataset_test, dataset_val = build_datasets(\n",
    "    TIKTOK_DATASET_SENTENCES,\n",
    "    test_size=0.3,\n",
    "    val_size=0.5, # 0.5 de 0.3    \n",
    "    random_state=42\n",
    ")\n",
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)\n",
    "print(dataset_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: es_core_news_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13727/13727 [00:12<00:00, 1066.98it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2942/2942 [00:02<00:00, 1086.47it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2942/2942 [00:02<00:00, 1136.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.preprocesamiento.nlp_spacy import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "dataset_train_tokenized = {}\n",
    "dataset_val_tokenized = {}\n",
    "dataset_test_tokenized = {}\n",
    "\n",
    "dataset_train_tokenized['tokens'] = tokenizer.tokenize(dataset_train['text'], True)\n",
    "dataset_val_tokenized['tokens'] = tokenizer.tokenize(dataset_val['text'], True)\n",
    "dataset_test_tokenized['tokens'] = tokenizer.tokenize(dataset_test['text'], True)\n",
    "\n",
    "dataset_train_tokenized['polarity'] = dataset_train['polarity'].to_numpy()\n",
    "dataset_val_tokenized['polarity'] = dataset_val['polarity'].to_numpy()\n",
    "dataset_test_tokenized['polarity'] = dataset_test['polarity'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001      0.00473151 0.02238721 0.10592537 0.50118723]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.trainers.utils import ModelArgs, EarlyStopping \n",
    "from constants.constants_tiktok import EMBEDDING_W2V_TIKTOK_SENTENCES_PATH\n",
    "\n",
    "list_pooling = [\"aver\", \"max\"]\n",
    "list_optim = [\"adam\", \"sgd\"]\n",
    "batch_size = 64\n",
    "list_lr = np.logspace(-3, -0.3, 5)\n",
    "print(list_lr)\n",
    "epochs = 50\n",
    "\n",
    "patience = 15\n",
    "min_delta = 1e-4\n",
    "\n",
    "model_args = ModelArgs()\n",
    "model_args.hidden_layers = [128, 64] # 128 bad\n",
    "model_args.output_size = 3\n",
    "model_args.dropout = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.trainers.train_mlp import train_mlp\n",
    "from src.trainers.utils import show_loss_val_curves, save_model_torch\n",
    "from constants.constants_tiktok import MLP_SWEM_LOSS_CURVES_DIR, MLP_SWEM_MODEL_PATH, TIKTOK_MLP_SWEM_METRICS_PATH\n",
    "\n",
    "best_accuracy = -1\n",
    "for pooling in list_pooling:\n",
    "    for optim in list_optim:\n",
    "        for lr in list_lr:\n",
    "            model, metrics, train_losses, val_losses = train_mlp(\n",
    "                dataset_train=dataset_train_tokenized,\n",
    "                dataset_val=dataset_val_tokenized,\n",
    "                embeddings_path=EMBEDDING_W2V_TIKTOK_SENTENCES_PATH,\n",
    "                model_args=model_args,\n",
    "                early_stopping = EarlyStopping(patience, min_delta),\n",
    "                batch_size=batch_size,\n",
    "                lr=lr,\n",
    "                epochs=epochs,\n",
    "                optim=optim,\n",
    "                pooling=pooling,\n",
    "                use_class_weights=True\n",
    "            )\n",
    "            print(f\"[MLP {pooling} {optim} {lr} ({model_args.hidden_layers}) {model_args.dropout}] acc: {metrics['accuracy']:.4f}\")\n",
    "            save_metrics(metrics, TIKTOK_MLP_SWEM_METRICS_PATH)\n",
    "            title = f\"MLP_SWEM_{metrics['pooling']}_{metrics['optim']} {'-'.join(str(lr).split('.'))}\"\n",
    "            path = os.path.join(MLP_SWEM_LOSS_CURVES_DIR, f\"{title}.png\")\n",
    "            show_loss_val_curves(train_losses, val_losses, len(train_losses), path)\n",
    "            if metrics['accuracy'] > best_accuracy:\n",
    "                best_accuracy = metrics['accuracy']\n",
    "                save_model_torch(model.get_model(), MLP_SWEM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con mayor accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy               0.35588\n",
      "recall                0.355883\n",
      "precision             0.355943\n",
      "f1_score              0.355874\n",
      "model                 MLP SWEM\n",
      "pooling                   aver\n",
      "optim                     adam\n",
      "lr                    0.001292\n",
      "patience                   NaN\n",
      "min_delta               0.0001\n",
      "hidden_layers    [128, 64, 32]\n",
      "output_size                  3\n",
      "dropout                    0.2\n",
      "epochs                     100\n",
      "batch_size                 128\n",
      "embedding_dim              100\n",
      "train_time           30.543442\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Seleccionar los hiperpar√°metros que generan mayor accuracy\n",
    "df_metrics = pd.read_csv(TIKTOK_MLP_SWEM_METRICS_PATH)\n",
    "\n",
    "best_acc = df_metrics.loc[df_metrics['accuracy'].idxmax()]\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from src.trainers.utils import load_model_torch, ModelArgs\n",
    "from src.trainers.train_mlp import evaluate_model, MLPModelCustom\n",
    "from constants.constants_tiktok import MLP_SWEM_MODEL_PATH, EMBEDDING_W2V_TIKTOK_SENTENCES_PATH\n",
    "\n",
    "model_args = ModelArgs()\n",
    "model_args.input_size = best_acc['embedding_dim']\n",
    "model_args.hidden_layers = [int(layer) for layer in re.findall(r\"\\d+\", best_acc['hidden_layers'])]\n",
    "model_args.output_size = 3\n",
    "model_args.dropout = best_acc['dropout']\n",
    "\n",
    "model = MLPModelCustom(model_args)\n",
    "model = load_model_torch(model, MLP_SWEM_MODEL_PATH)\n",
    "\n",
    "metrics = evaluate_model(\n",
    "    model,\n",
    "    dataset_test_tokenized,\n",
    "    \"MLP\",\n",
    "    EMBEDDING_W2V_TIKTOK_SENTENCES_PATH,\n",
    "    best_acc['pooling'],\n",
    "    64\n",
    ")\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.train_mlp import SentimentAnalysis\n",
    "\n",
    "cls = SentimentAnalysis(model, EMBEDDING_W2V_TIKTOK_SENTENCES_PATH, tokenizer, \"cpu\", \"aver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: es_core_news_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1245.12it/s]\n",
      "5it [00:00, 455.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando stemming...\n",
      "Total de documentos preprocesados: 5\n",
      "[('NEU', 0.8706167936325073), ('POS', 0.12933428585529327), ('NEG', 4.89312042191159e-05)]\n",
      "[('POS', 0.6948035359382629), ('NEU', 0.3051930069923401), ('NEG', 3.491584266157588e-06)]\n",
      "[('NEG', 0.9999744892120361), ('NEU', 2.5472378183621913e-05), ('POS', 1.0228039160369317e-19)]\n",
      "[('NEU', 0.9985527396202087), ('NEG', 0.0009148080134764314), ('POS', 0.0005324697121977806)]\n",
      "[('POS', 0.7565785050392151), ('NEG', 0.23506490886211395), ('NEU', 0.008356570266187191)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.preprocesamiento.clean import clean_text\n",
    "from src.preprocesamiento.nlp_spacy import preprocesamiento\n",
    "\n",
    "textos_test = [\"Hola! c√≥mo est√°s???üòÄ\",\"el dia de hoy estoy feliz y contento\", \"estoy muy triste\", \"Me encuentro estudiando para un ex√°men\", \"A veces me encuentro triste, pero la mayoria del tiempo estoy muy feliz\"]\n",
    "textos_test = list(map(lambda x: clean_text(x), textos_test))\n",
    "textos_test = preprocesamiento(textos_test)\n",
    "for texto in textos_test:\n",
    "    print(cls.predict(texto))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
