{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - TikTok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Agregar el directorio raiz al PYTHONPATH\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar modelo de SVM para entrenarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.train_svm import train_svm\n",
    "from src.trainers.utils import build_datasets, save_metrics\n",
    "from constants.constants_twitter import TWITTER_DATASET_TRAIN_PATH\n",
    "\n",
    "dataset_train, dataset_test, dataset_val = build_datasets(\n",
    "    TWITTER_DATASET_TRAIN_PATH,\n",
    "    test_size=0.3,\n",
    "    val_size=0.5, # 0.5 de 0.3    \n",
    "    random_state=42\n",
    ")\n",
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)\n",
    "print(dataset_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "list_kernel = [\"linear\", \"rbf\", 'poly']\n",
    "list_vectorizers = [\"tfidf\", \"bow\"]\n",
    "list_C = np.logspace(-2, 1, 20)\n",
    "print(list_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.constants_twitter import SVM_PIPELINE_PATH, TWITTER_SVM_METRICS_PATH\n",
    "from src.trainers.utils import save_model\n",
    "\n",
    "best_accuracy = -1\n",
    "for vectorizer in list_vectorizers:\n",
    "    for kernel in list_kernel:\n",
    "        for C in list_C:\n",
    "            pipeline, metrics = train_svm(\n",
    "                dataset_train,\n",
    "                dataset_val,\n",
    "                C=C,\n",
    "                kernel=kernel,\n",
    "                vec=vectorizer\n",
    "            )\n",
    "            print(f\"SVM {vectorizer} {kernel} {C}: {metrics['accuracy']}\")\n",
    "            save_metrics(metrics, TWITTER_SVM_METRICS_PATH)\n",
    "            # Guardar Pipeline\n",
    "            if metrics['accuracy'] > best_accuracy:\n",
    "                save_model(pipeline, SVM_PIPELINE_PATH)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo con mayor accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los hiperpar√°metros que generan mayor accuracy\n",
    "df_metrics = pd.read_csv(TWITTER_SVM_METRICS_PATH)\n",
    "\n",
    "best_acc = df_metrics.loc[df_metrics['accuracy'].idxmax()]\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.utils import evaluate_model\n",
    "from src.trainers.utils import load_model\n",
    "from constants.constants_twitter import SVM_PIPELINE_PATH\n",
    "\n",
    "# Evaluar modelo con datos de prueba\n",
    "pipeline = load_model(SVM_PIPELINE_PATH)\n",
    "metrics = evaluate_model(pipeline, dataset_test, title=\"Support Vector Machine\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.constants_nlp import INDEX_TO_POLARITY\n",
    "from src.preprocesamiento.clean import clean_text\n",
    "from src.preprocesamiento.nlp_spacy import preprocesamiento\n",
    "\n",
    "textos_test = [\"i'm study hard\", \"i'm happy\"]\n",
    "textos_test = list(map(lambda x: clean_text(x, \"en\"), textos_test))\n",
    "textos_test = preprocesamiento(textos_test, stemming=True, lang=\"en\")\n",
    "\n",
    "preds = pipeline.predict(textos_test)\n",
    "for input, pred in zip(textos_test,preds):\n",
    "    print(f\"{input}: {INDEX_TO_POLARITY[pred]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
